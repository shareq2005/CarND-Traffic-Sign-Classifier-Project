{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data, and the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load pickled data\n",
    "training_file = 'train.p'\n",
    "validation_file= 'valid.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "Sizes_train = train['sizes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "# Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# Number of validation examples\n",
    "n_validation = len(X_valid)\n",
    "\n",
    "# Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAEYCAYAAACqUwbqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a104160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Data exploration visualization code\n",
    "%matplotlib inline\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(15, 4))\n",
    "\n",
    "#counts of each unique sign\n",
    "counts_train = np.unique(y_train,return_counts = True)\n",
    "counts_valid = np.unique(y_valid,return_counts = True)\n",
    "counts_test  = np.unique(y_test,return_counts = True)\n",
    "\n",
    "#convert to numpy array\n",
    "counts_train_arr = np.array(counts_train)\n",
    "counts_valid_arr = np.array(counts_valid)\n",
    "counts_test_arr  = np.array(counts_test)\n",
    "\n",
    "#distribution of training, validation and testing sets\n",
    "distrib_train = (counts_train_arr/n_train) * 100 \n",
    "distrib_valid = (counts_valid_arr/n_validation) * 100\n",
    "distrib_test  = (counts_test_arr/n_test) * 100\n",
    "\n",
    "width = 0.5\n",
    "\n",
    "ax0.bar(counts_train[0],distrib_train[1], width, color=\"blue\")\n",
    "ax1.bar(counts_valid[0],distrib_valid[1], width, color=\"red\")\n",
    "ax2.bar(counts_test[0],distrib_test[1], width, color=\"green\")\n",
    "\n",
    "ax0.set_title('Distribution of Training Set %')\n",
    "ax1.set_title('Distribution of Validation Set %')\n",
    "ax2.set_title('Distribution of Testing Set %')\n",
    "\n",
    "ax0.set_xlabel('Traffic Index')\n",
    "ax1.set_xlabel('Traffic Index')\n",
    "ax2.set_xlabel('Traffic Index')\n",
    "\n",
    "ax0.set_ylabel('% of distribution')\n",
    "ax1.set_ylabel('% of distribution')\n",
    "ax2.set_ylabel('% of distribution')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization and grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle the images\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d4fc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def GrayscaleImage(pixel_data):\n",
    "    grayscaled_image = cv2.cvtColor(pixel_data, cv2.COLOR_RGB2GRAY)        \n",
    "    grayscaled_image = grayscaled_image.reshape(32,32,1)\n",
    "    return grayscaled_image\n",
    "\n",
    "def CreateGrayscaleImageArray(X_data):\n",
    "    X_data = np.array([GrayscaleImage(X_data[i]) for i in range(len(X_data))])\n",
    "    return X_data\n",
    "\n",
    "#Grayscale the training, validation and testing sets\n",
    "X_train_gray = CreateGrayscaleImageArray(X_train)\n",
    "X_valid_gray = CreateGrayscaleImageArray(X_valid)\n",
    "X_test_gray  = CreateGrayscaleImageArray(X_test)\n",
    "\n",
    "#Print a random image\n",
    "index = random.randint(0, len(X_train_gray))\n",
    "image = X_train_gray[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize the training, validation & testing sets\n",
    "X_train_gray = (X_train_gray - 128.0)/128.0\n",
    "X_valid_gray = (X_valid_gray - 128.0)/128.0\n",
    "X_test_gray  = (X_test_gray  - 128.0)/128.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def TrafficClassifierNet(x,keep_prob):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x24.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 24), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(24))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1   = tf.nn.relu(conv1)\n",
    "    conv1   = tf.nn.dropout(conv1,keep_prob)\n",
    "    \n",
    "    # Layer 2: Pooling. Input = 28x28x24. Output = 14x14x24.\n",
    "    maxp2 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    maxp2 = tf.nn.dropout(maxp2,keep_prob)\n",
    "    \n",
    "    # Layer 3: Convolutional. Input = 14x14x24. Output = 10x10x48.\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 24, 48), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(48))\n",
    "    conv3   = tf.nn.conv2d(maxp2, conv3_W, strides=[1, 1, 1, 1], padding='VALID') + conv3_b\n",
    "    conv3   = tf.nn.relu(conv3)\n",
    "    conv3   = tf.nn.dropout(conv3,keep_prob)\n",
    "    \n",
    "    # Layer 4: Pooling. Input = 10x10x48. Output = 5x5x48.\n",
    "    maxp4 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    maxp4 = tf.nn.dropout(maxp4,keep_prob)\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x48. Output = 1200.\n",
    "    flat5   = flatten(maxp4)\n",
    "    \n",
    "    # Layer 5: Fully Connected. Input = 1200. Output = 480.\n",
    "    fc5_W = tf.Variable(tf.truncated_normal(shape=(1200, 480), mean = mu, stddev = sigma))\n",
    "    fc5_b = tf.Variable(tf.zeros(480))\n",
    "    fc5   = tf.matmul(flat5, fc5_W) + fc5_b\n",
    "    fc5    = tf.nn.relu(fc5)\n",
    "    fc5    = tf.nn.dropout(fc5,keep_prob)\n",
    "    \n",
    "    # Layer 6: Fully Connected. Input = 480. Output = 240.\n",
    "    fc6_W  = tf.Variable(tf.truncated_normal(shape=(480, 240), mean = mu, stddev = sigma))\n",
    "    fc6_b  = tf.Variable(tf.zeros(240))\n",
    "    fc6    = tf.matmul(fc5, fc6_W) + fc6_b    \n",
    "    fc6    = tf.nn.relu(fc6)\n",
    "    fc6    = tf.nn.dropout(fc6,keep_prob)\n",
    "    \n",
    "    # Layer 7: Fully Connected. Input = 240. Output = 43.\n",
    "    fc7_W  = tf.Variable(tf.truncated_normal(shape=(240, 43), mean = mu, stddev = sigma))\n",
    "    fc7_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc6, fc7_W) + fc7_b\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = TrafficClassifierNet(x,keep_prob)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluation of the loss and accuracy of the model for the German Traffic Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y,keep_prob:1.})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.176\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.500\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.718\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.812\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.855\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.875\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.903\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.908\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.918\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.936\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.949\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.939\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.943\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 26 ...\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "EPOCH 27 ...\n",
      "Validation Accuracy = 0.951\n",
      "\n",
      "EPOCH 28 ...\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "EPOCH 29 ...\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "EPOCH 30 ...\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "EPOCH 31 ...\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "EPOCH 32 ...\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "EPOCH 33 ...\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "EPOCH 34 ...\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "EPOCH 35 ...\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 36 ...\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "EPOCH 37 ...\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "EPOCH 38 ...\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 39 ...\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "EPOCH 40 ...\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "EPOCH 41 ...\n",
      "Validation Accuracy = 0.963\n",
      "\n",
      "EPOCH 42 ...\n",
      "Validation Accuracy = 0.964\n",
      "\n",
      "EPOCH 43 ...\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "EPOCH 44 ...\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 45 ...\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 46 ...\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 47 ...\n",
      "Validation Accuracy = 0.960\n",
      "\n",
      "EPOCH 48 ...\n",
      "Validation Accuracy = 0.952\n",
      "\n",
      "EPOCH 49 ...\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "EPOCH 50 ...\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train_gray)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train_gray, y_train = shuffle(X_train_gray, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train_gray[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y,keep_prob:0.6})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid_gray, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing set accuracy for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 99.9 %\n",
      "The accuracy on the test set is 95.7 %\n"
     ]
    }
   ],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, './lenet')\n",
    "    train_set_accuracy = evaluate(X_train_gray, y_train) * 100\n",
    "    test_set_accuracy  = evaluate(X_test_gray, y_test) * 100\n",
    "\n",
    "print(\"The accuracy on the training set is {:.1f} %\".format(train_set_accuracy))\n",
    "print(\"The accuracy on the test set is {:.1f} %\".format(test_set_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWT0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1190aaf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Load the images and plot them here.\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the examples images and the mappings found on the internet\n",
    "traffic_sign_example_images   = ['0.png','1.png','2.png','3.png','4.png','5.png','6.png','7.png','8.png', '9.png']\n",
    "traffic_sign_example_mappings = [2,12,3,39,28,1,28,35,22,13]\n",
    "\n",
    "image_array = []\n",
    "\n",
    "for i in range(0, len(traffic_sign_example_images)):\n",
    "    test_image = cv2.imread('Traffic-Sign-Examples/' + traffic_sign_example_images[i])\n",
    "    image_array.append(test_image)\n",
    "\n",
    "# Grayscale the example\n",
    "X_test_images = CreateGrayscaleImageArray(image_array)\n",
    "\n",
    "# Output a random image\n",
    "index = random.randint(0, len(X_test_images)-1)\n",
    "image = X_test_images[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(traffic_sign_example_mappings[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocess - normalize the example images\n",
    "test_images_grayscaled = (X_test_images - 128.0)/128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 index = 2, predicted index = 2\n",
      "Image 1 index = 12, predicted index = 12\n",
      "Image 2 index = 3, predicted index = 3\n",
      "Image 3 index = 39, predicted index = 39\n",
      "Image 4 index = 28, predicted index = 1\n",
      "Image 5 index = 1, predicted index = 1\n",
      "Image 6 index = 28, predicted index = 28\n",
      "Image 7 index = 35, predicted index = 35\n",
      "Image 8 index = 22, predicted index = 22\n",
      "Image 9 index = 13, predicted index = 13\n"
     ]
    }
   ],
   "source": [
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "prediction = tf.argmax(logits, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, './lenet')\n",
    "    predicted_index = sess.run(prediction,feed_dict={x: test_images_grayscaled, keep_prob:1.0})\n",
    "\n",
    "for i in range(len(test_images_grayscaled)):\n",
    "    print(\"Image {} index = {}, predicted index = {}\".format(i, traffic_sign_example_mappings[i], predicted_index[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the example images from the internet is 90.0 %\n"
     ]
    }
   ],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, './lenet')\n",
    "    validation_accuracy_percentage = evaluate(test_images_grayscaled, traffic_sign_example_mappings) * 100\n",
    "\n",
    "print(\"The accuracy on the example images from the internet is {:.1f} %\".format(validation_accuracy_percentage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0, Real Index = 2, top 5 softmax probabilites:\n",
      "\t Index = 2, Probability = 0.9990\n",
      "\t Index = 5, Probability = 0.0008\n",
      "\t Index = 1, Probability = 0.0001\n",
      "\t Index = 7, Probability = 0.0000\n",
      "\t Index = 3, Probability = 0.0000\n",
      "Image 1, Real Index = 12, top 5 softmax probabilites:\n",
      "\t Index = 12, Probability = 1.0000\n",
      "\t Index = 40, Probability = 0.0000\n",
      "\t Index = 9, Probability = 0.0000\n",
      "\t Index = 38, Probability = 0.0000\n",
      "\t Index = 11, Probability = 0.0000\n",
      "Image 2, Real Index = 3, top 5 softmax probabilites:\n",
      "\t Index = 3, Probability = 0.9510\n",
      "\t Index = 2, Probability = 0.0388\n",
      "\t Index = 5, Probability = 0.0101\n",
      "\t Index = 1, Probability = 0.0001\n",
      "\t Index = 10, Probability = 0.0000\n",
      "Image 3, Real Index = 39, top 5 softmax probabilites:\n",
      "\t Index = 39, Probability = 0.8568\n",
      "\t Index = 2, Probability = 0.1222\n",
      "\t Index = 1, Probability = 0.0072\n",
      "\t Index = 40, Probability = 0.0054\n",
      "\t Index = 7, Probability = 0.0018\n",
      "Image 4, Real Index = 28, top 5 softmax probabilites:\n",
      "\t Index = 1, Probability = 0.1355\n",
      "\t Index = 36, Probability = 0.1076\n",
      "\t Index = 18, Probability = 0.0891\n",
      "\t Index = 25, Probability = 0.0822\n",
      "\t Index = 6, Probability = 0.0732\n",
      "Image 5, Real Index = 1, top 5 softmax probabilites:\n",
      "\t Index = 1, Probability = 0.9992\n",
      "\t Index = 0, Probability = 0.0005\n",
      "\t Index = 2, Probability = 0.0003\n",
      "\t Index = 4, Probability = 0.0000\n",
      "\t Index = 5, Probability = 0.0000\n",
      "Image 6, Real Index = 28, top 5 softmax probabilites:\n",
      "\t Index = 28, Probability = 1.0000\n",
      "\t Index = 29, Probability = 0.0000\n",
      "\t Index = 20, Probability = 0.0000\n",
      "\t Index = 11, Probability = 0.0000\n",
      "\t Index = 24, Probability = 0.0000\n",
      "Image 7, Real Index = 35, top 5 softmax probabilites:\n",
      "\t Index = 35, Probability = 1.0000\n",
      "\t Index = 3, Probability = 0.0000\n",
      "\t Index = 36, Probability = 0.0000\n",
      "\t Index = 33, Probability = 0.0000\n",
      "\t Index = 34, Probability = 0.0000\n",
      "Image 8, Real Index = 22, top 5 softmax probabilites:\n",
      "\t Index = 22, Probability = 0.9951\n",
      "\t Index = 29, Probability = 0.0049\n",
      "\t Index = 15, Probability = 0.0000\n",
      "\t Index = 28, Probability = 0.0000\n",
      "\t Index = 26, Probability = 0.0000\n",
      "Image 9, Real Index = 13, top 5 softmax probabilites:\n",
      "\t Index = 13, Probability = 1.0000\n",
      "\t Index = 1, Probability = 0.0000\n",
      "\t Index = 12, Probability = 0.0000\n",
      "\t Index = 35, Probability = 0.0000\n",
      "\t Index = 9, Probability = 0.0000\n"
     ]
    }
   ],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "softmax_probabilities = tf.nn.softmax(logits)\n",
    "top_five_probs = tf.nn.top_k(softmax_probabilities, k=5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './lenet')\n",
    "    top_five_probs_out = sess.run(top_five_probs, feed_dict={x: test_images_grayscaled, keep_prob:1.0})\n",
    "\n",
    "#print(top_five_probs_out)\n",
    "\n",
    "for i in range(len(test_images_grayscaled)):\n",
    "    print('Image {}, Real Index = {}, top 5 softmax probabilites:'.format(i,traffic_sign_example_mappings[i]))\n",
    "    \n",
    "    for j in range(5):\n",
    "        print('\\t Index = {}, Probability = {:.4f}'.format(top_five_probs_out.indices[i][j], top_five_probs_out.values[i][j]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
